# 使用流程示例

## 步驟 1：啟動應用

### EXE 用戶
```
rag_qa_app.exe
```

### Python 用戶
```bash
python launcher.py
```

應該看到：
```
INFO:     Started server process [27676]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
```

## 步驟 2：打開瀏覽器

訪問：http://127.0.0.1:8000

應該看到：
- 左側：📄 知識庫管理面板（文檔上傳）
- 右側：❓ 提出問題面板（QA 介面）

## 步驟 3：上傳文檔

### 準備文件
創建一個測試文件 `example.txt`：
```
Python 是一種解釋型高級程式語言。Python 由 Guido van Rossum 於 1989 年創立。
Python 語法簡潔，易於學習。Python 支持物件導向、命令式和函數式編程範式。
Python 可用於 Web 開發、數據分析、機器學習、自動化等領域。
```

### 上傳步驟
1. 點擊左側"➕ 選擇文檔上傳"按鈕
2. 選擇 `example.txt`
3. 等待上傳完成（應看到綠色✅成功訊息）
4. 文檔會自動出現在"已上傳文檔"列表

### 預期結果
```
✅ Document processed successfully
分割為 2 個片段，生成了 2 個向量化表示
```

## 步驟 4：提問

### 測試問題 1
**問題：** `Python 是什麼？`

**預期輸出：**
```
🤖 RAG 回答 (基於知識庫):
根據上傳的文檔，Python 是一種解釋型高級程式語言，由 Guido van Rossum 於 1989 年創立。
Python 語法簡潔，易於學習，支持多種編程範式...

———————————————————————————————

💭 基礎回答 (沒有知識庫):
Python 是一種通用的、高級的編程語言...

———————————————————————————————

📚 相關來源文檔:

1. example.txt_chunk_0
   相似度分數: 0.8542
   内容: Python 是一種解釋型高級程式語言。Python 由 Guido van Rossum...

———————————————————————————————

⏱️  處理耗時:
   文檔檢索: 12.34ms
   RAG 模型推理: 1234.56ms
   基礎模型推理: 1200.34ms
```

### 測試問題 2
**問題：** `Python 可以做什麼？`

**預期結果：**
- RAG 回答會提及文檔中的具體應用領域（Web、數據分析等）
- 基礎回答則是通用的 Python 用途
- 可以清楚看到知識庫對答案的影響

## 步驟 5：文檔管理

### 查看已上傳文檔
文檔自動顯示在左側面板：
```
📄 example.txt
分割數: 2 | 字數: 450
[刪除]
```

### 刪除文檔
1. 點擊文檔旁的"刪除"按鈕
2. 確認刪除
3. 文檔和相關向量會被移除
4. 列表會自動更新

## 完整工作流示例

```
1. 啟動應用
   ↓
2. 上傳技術文檔（含 Python、JavaScript 內容）
   ↓
3. 提問："最流行的 Web 框架是什麼？"
   ↓
4. 獲得基於知識庫的精準回答
   ↓
5. 如果內容不相關，可以上傳更多文檔
   ↓
6. 刪除不需要的文檔
   ↓
7. 繼續提問
```

## 📊 性能預期

| 操作 | 耗時 |
|------|------|
| 文檔上傳 (100KB) | <5 秒 |
| 文檔檢索 | <50ms |
| LLM 推理 | 2-10 秒 |
| **總耗時** | **2-15 秒** |

*實際耗時取決於 CPU、模型大小和硬件配置*

## 🔧 故障排除

### 上傳後沒看到文檔
- 檢查網絡連接
- 檢查檔案大小（>50MB 可能超時）
- 刷新頁面 F5

### 提問沒有回答
- 檢查是否上傳了相關文檔
- 檢查瀏覽器控制台（F12）看是否有錯誤
- 確保模型已正確加載（查看終端輸出）

### 提問很慢
- 這是正常的（LLM 推理需要時間）
- 可以增加 LLAMA_THREADS 加快速度
- 使用更小的模型（Q4 代替 Q5）

### 刪除後重新上傳同名文件
- 完全刪除舊的嵌入和文檔
- 新文件會被當作新的知識庫內容

## 💡 最佳實踐

1. **文檔組織**
   - 上傳相關主題的文檔
   - 避免過多不相關的文檔（會降低檢索精度）

2. **提問方式**
   - 使用清晰、具體的問題
   - 提供足夠的上下文
   - 避免模棱兩可的表述

3. **性能優化**
   - 定期清理不需要的文檔
   - 使用量化的模型（Q4_K_M）以加快推理
   - 設置合理的 LLAMA_THREADS

4. **質量提升**
   - 上傳高質量的源文檔
   - 文檔內容越相關，RAG 回答越精準
   - 可以嘗試不同的 LLM 模型

## 📚 更多資源

- [完整部署指南](./DEPLOYMENT_GUIDE.md)
- [API 文檔](./DEPLOYMENT_GUIDE.md#-api-文檔)
- [模型推薦](./DEPLOYMENT_GUIDE.md#-lvm-模型推薦)
- [故障排除](./DEPLOYMENT_GUIDE.md#-故障排除)
